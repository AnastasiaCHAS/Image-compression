{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_compression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSe3MsHA99KV"
      },
      "source": [
        "# Сжатие изображений \n",
        "\n",
        "Преобразование картинок размера [3,512,512] в тензоры [6, 128, 128]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64Bkd-Xg8lZu"
      },
      "source": [
        "# для использования оптимизатора RAdam\n",
        "!pip install torch_optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTNk2aPLCDDN"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        " \n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from pathlib import Path\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "import argparse\n",
        "import os\n",
        "from threading import Thread\n",
        " \n",
        " \n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        " \n",
        "%pylab inline\n",
        "import matplotlib.pylab as plt\n",
        " \n",
        "import copy\n",
        "import datetime\n",
        "#import traceback\n",
        "import logging\n",
        "import torch_optimizer as optim\n",
        " \n",
        "\n",
        "seed = 37\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIs2qFy-DPxQ"
      },
      "source": [
        "### Для обучения использовала dataset с Kaggle: \n",
        "\n",
        "---\n",
        "\n",
        "https://www.kaggle.com/andrewmvd/animal-faces\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVmXRlBBCT25"
      },
      "source": [
        "!mkdir dog"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpDalWPtFElG"
      },
      "source": [
        "!unzip ./data/dog.zip -d /content/dog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xFeeI5HSQRw"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument(\"--epoches\", type=int, default=100, help=\"Number of epochs\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=12, help=\"Batch size of train\")\n",
        "parser.add_argument(\"--lambda_L1\", type=float, default=0.02, help=\"lambda for L1-regularization\")\n",
        "parser.add_argument(\"--lambda_L2\", type=float, default=0.01, help=\"lambda for L2-regularization\")\n",
        "parser.add_argument(\"--learn_rate\", type=float, default=0.001, help=\"Learning rate\")\n",
        "parser.add_argument(\"--shed_patience\", type=int, default=5, help=\"Sheduler patience\")\n",
        "parser.add_argument(\"--optimizer\", type=str, default=\"Adam\", help=\"Type optimizer\")\n",
        "parser.add_argument(\"--fast\", type=bool, default=True, help=\"cudnn.benchmark\")\n",
        "\n",
        "try:\n",
        "    opt = parser.parse_args()\n",
        "    opt.colab=False    \n",
        "except:\n",
        "    opt = parser.parse_args(args=[])\n",
        "    opt.colab=True\n",
        "if opt.colab:\n",
        "    output = print\n",
        "    path = \"...\"    \n",
        "    path_result = \"...\"\n",
        "    opt.workers = 4\n",
        "else:\n",
        "    opt.starttimestr = datetime.datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
        "    logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(message)s\",\n",
        "                        handlers=[logging.FileHandler(os.path.join(\"logs\",opt.starttimestr+\".log\")),\n",
        "                                  logging.StreamHandler()])\n",
        "    output = logging.info\n",
        "    path = \"input\"    \n",
        "    path_result = \"models\"\n",
        "    opt.workers = min(opt.batch_size, 16)\n",
        "np.set_printoptions(precision=3, linewidth=np.inf, edgeitems=5)\n",
        "torch.set_default_tensor_type(torch.FloatTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8viUYBCiFFML"
      },
      "source": [
        "# путь к данным\n",
        "path = [\"/content/dog/dog/afhq/train\"]\n",
        "\n",
        "# путь к папке, куда сохраняются модели, картинки\n",
        "path_result = \"./saved_models\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3nKwqO4f-Kq"
      },
      "source": [
        "### Класс *DogDataset* формирует тренировочную, валидационную и тестовую выборки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eH2opFxFfvu"
      },
      "source": [
        "class DogDataset(Dataset):\n",
        "  def __init__(self,path,flag,cache=False):\n",
        "    # если flag=0 - обучение     ----60%\n",
        "    # если flag=1 - валидация    ----20%\n",
        "    # если flag=2 - тестирование ----20%\n",
        "    mas = []\n",
        "    for p in path:\n",
        "      for root, dirs, files in os.walk(p):\n",
        "        mas += list(map(lambda y:os.path.join(root,y),files))\n",
        "    mas = sorted(mas)\n",
        "    random.shuffle(mas)\n",
        "    if flag==0:\n",
        "      self.my_path = mas[:int(0.61518*len(mas))]\n",
        "    elif flag==1:\n",
        "      self.my_path = mas[int(0.61518*len(mas)):int(0.82024*len(mas))]\n",
        "    else:\n",
        "      self.my_path = mas[int(0.82024*len(mas)):]\n",
        "\n",
        "    print(\"Количество файлов:\", len(self.my_path))\n",
        "\n",
        "    self.cache = cache\n",
        "    if self.cache:\n",
        "       self.cdata = [None]*self.__len__()\n",
        "       thread = [None]*opt.workers\n",
        "       for index in range(self.__len__()+len(thread)):\n",
        "           i = index%len(thread)\n",
        "           if thread[i] is not None:\n",
        "              thread[i].join()\n",
        "              thread[i]=None\n",
        "           if index < self.__len__():\n",
        "              thread[i] = Thread(target=self.__getitem__, args=(index,))\n",
        "              thread[i].start()\n",
        "  \n",
        "  def __len__(self):\n",
        "    return(len(self.my_path))\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    if self.cache and self.cdata[index] is not None:\n",
        "      return self.cdata[index]\n",
        "\n",
        "    \n",
        "    file = self.my_path[index % len(self.my_path)]\n",
        "    #все полученные картинки получат один размер 512*512\n",
        "    trans = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])\n",
        "    \n",
        "    image = trans(Image.open(file)) # тензор размером [3,512,512], где значения от 0 до 1\n",
        "    image = image[:3,:,:]\n",
        "    if image.shape[0]==1:\n",
        "      image = torch.cat((image,image,image))\n",
        "    \n",
        "    if self.cache:\n",
        "        self.cdata[index] = image\n",
        "    return image"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNbPtVxtgm_N"
      },
      "source": [
        "### Архитектура нейронной сети\n",
        "\n",
        "Архитектура нейронной сети - encoder-decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKOBYmWlFpIQ"
      },
      "source": [
        "class Layer(torch.nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,         # количество входных канлов\n",
        "               out_channels,        # количество каналов после применения слоя\n",
        "               kernel_size,         # размер ядра свёртки\n",
        "               stride,              # размер шага\n",
        "               padding,             # размер паддинга \n",
        "               flag,                # \"encoder\" or \"decoder\"\n",
        "               batch_norm,          # булевая переменная: надо ли применять батч нормализацию\n",
        "               drop,                # вероятность в Dropout\n",
        "               activation):         # функция активации\n",
        "    \n",
        "    super(Layer, self).__init__()\n",
        "    lay=[]\n",
        "    if flag== \"encoder\":\n",
        "      lay.append(torch.nn.Conv2d(in_channels, out_channels, \n",
        "                                 kernel_size=kernel_size, stride=stride, padding=padding))\n",
        "    else:\n",
        "      lay.append(torch.nn.ConvTranspose2d(in_channels, out_channels, \n",
        "                                          kernel_size=kernel_size, stride=stride, padding=padding))\n",
        "    \n",
        "    if batch_norm==True:\n",
        "      lay.append(torch.nn.BatchNorm2d(out_channels))\n",
        "    \n",
        "    if drop == True:\n",
        "      lay.append(torch.nn.Dropout(0.5)) \n",
        "   \n",
        "    if activation == \"leakyReLU\":\n",
        "      lay.append(torch.nn.LeakyReLU(0.2))\n",
        "    elif activation == \"reLU\":\n",
        "      lay.append(torch.nn.ReLU())\n",
        "    elif activation == \"sigmoid\":\n",
        "      lay.append(torch.nn.Sigmoid())\n",
        "    \n",
        "    self.layer = torch.nn.Sequential(*lay)\n",
        "\n",
        "\n",
        "  def forward(self,data):\n",
        "      return self.layer(data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orJ2-GUgHQui"
      },
      "source": [
        "sigmoida = torch.nn.Sigmoid()\n",
        "\n",
        "class Net_encoder_decoder(torch.nn.Module):\n",
        "  def __init__(self,\n",
        "               k_s =3,    #kernel_size\n",
        "               strid=1,   #stride\n",
        "               pad=1,     #padding\n",
        "               canal = 32):   #channals\n",
        "    super(Net_encoder_decoder, self).__init__()\n",
        "\n",
        "    d = canal\n",
        "    self.encoder_0 = Layer(in_channels = 3, out_channels = d, \n",
        "                           kernel_size=k_s-1, stride=strid-1, padding=pad,\n",
        "                           flag = \"encoder\", batch_norm = True, drop = False, activation = \"leakyReLU\")\n",
        "    \n",
        "    self.encoder_1 = Layer(in_channels = d, out_channels = 2*d,\n",
        "                           kernel_size=k_s, stride=strid, padding=pad,\n",
        "                           flag = \"encoder\", batch_norm = True, drop = False, activation = \"leakyReLU\")\n",
        "    \n",
        "    self.encoder_1_p = Layer(in_channels = 2*d, out_channels = 4*d,\n",
        "                           kernel_size=k_s-1, stride=strid-1, padding=pad,\n",
        "                           flag = \"encoder\", batch_norm = True, drop = False, activation = \"leakyReLU\")\n",
        "    \n",
        "    self.encoder_2 = Layer(in_channels = 4*d, out_channels = 2*d,\n",
        "                           kernel_size=k_s, stride=strid, padding=pad,\n",
        "                           flag = \"encoder\", batch_norm = True, drop = False, activation = \"leakyReLU\")\n",
        "    \n",
        "    self.encoder_2_p = Layer(in_channels = 2*d, out_channels = 6,\n",
        "                           kernel_size=k_s-1, stride=strid-1, padding=pad,\n",
        "                           flag = \"encoder\", batch_norm = True, drop = False, activation = \"leakyReLU\")\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    self.decoder_3 = Layer(in_channels = 6, out_channels = d,\n",
        "                           kernel_size=k_s-1, stride=strid-1, padding=pad,\n",
        "                           flag = \"decoder\", batch_norm = True, drop = False, activation = \"reLU\")\n",
        "    \n",
        "    self.decoder_4 = Layer(in_channels = d, out_channels = 2*d,\n",
        "                           kernel_size=k_s, stride=strid, padding=pad,\n",
        "                           flag = \"decoder\", batch_norm = True, drop = False, activation = \"reLU\")\n",
        "    \n",
        "    self.decoder_5 = Layer(in_channels = 2*d, out_channels = d,\n",
        "                           kernel_size=k_s, stride=strid, padding=pad,\n",
        "                           flag = \"decoder\", batch_norm = True, drop = False, activation = \"reLU\")\n",
        "    \n",
        "    self.decoder_6 = Layer(in_channels = d, out_channels = 3,\n",
        "                           kernel_size=k_s-1, stride=strid-1, padding=pad,\n",
        "                           flag = \"decoder\", batch_norm = True, drop = False, activation = \"sigmoida\")\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder_0(x)\n",
        "    x = self.encoder_1(x)\n",
        "    x = self.encoder_1_p(x)\n",
        "    x = self.encoder_2(x)\n",
        "    x = self.encoder_2_p(x)\n",
        "    \n",
        "    x = self.decoder_3(x)\n",
        "    x = self.decoder_4(x)\n",
        "    x = self.decoder_5(x)\n",
        "    x = self.decoder_6(x)\n",
        "\n",
        "    return(x)\n",
        "\n",
        "\n",
        "  def encoded_1(self,x):\n",
        "    x = self.encoder_0(x)\n",
        "    x = self.encoder_1(x)\n",
        "    x = self.encoder_1_p(x)\n",
        "    x = self.encoder_2(x)\n",
        "    x = self.encoder_2_p(x)\n",
        "    return(x)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsYiJAW0kZaY"
      },
      "source": [
        "Инициализация весов модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UOvhrMcHYEv"
      },
      "source": [
        "def init_weight(x):\n",
        "  if type(x) == torch.nn.Conv2d or type(x) == torch.nn.ConvTranspose2d:\n",
        "    torch.nn.init.xavier_uniform(x.weight, gain = 0.95)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIZPFqMckfvi"
      },
      "source": [
        "### L1 - регуляризация "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk99lD6HHba2"
      },
      "source": [
        "def reg_L1(model):\n",
        "  s=-1;\n",
        "  for name, param in model.named_parameters():\n",
        "    s+=1\n",
        "    if s==0:\n",
        "      L1 = torch.sum(torch.abs(param))\n",
        "    else:\n",
        "      L1 += torch.sum(torch.abs(param))\n",
        "  \n",
        "  return(L1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmbWr1rWlSdA"
      },
      "source": [
        "### Функция потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSKkUKdSHeKB"
      },
      "source": [
        "class My_Loss(torch.nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(My_Loss, self).__init__()\n",
        "\n",
        "    def forward(self, preds, input, type_loss):\n",
        "\n",
        "      if type_loss == \"MSE\":\n",
        "        func_loss = torch.nn.MSELoss()\n",
        "        res = func_loss(preds, input) \n",
        "      elif type_loss == 'MAE':\n",
        "        func_loss = torch.nn.L1Loss()\n",
        "        res = func_loss(preds, input)\n",
        "      elif type_loss == 'MAE+MSE':\n",
        "        func_loss_1 = torch.nn.L1Loss()\n",
        "        func_loss = torch.nn.MSELoss()\n",
        "        res = func_loss(preds, input) + func_loss_1(preds, input) \n",
        "\n",
        "\n",
        "      return(res)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60CIuxB0lkNs"
      },
      "source": [
        "### Класс-тренер:\n",
        "\n",
        "А) элементы:\n",
        "1. модель\n",
        "2. оптимизатор\n",
        "3. планировщик\n",
        "4. функция потерь\n",
        "5. история значений функции потерь по эпохам на обучении\n",
        "6. история значений функции потерь по эпохам на валидации\n",
        "7. лучшая модель\n",
        "8. тип архитектуры нейронной сети\n",
        "9. коэффициент при L1-регуляризации\n",
        "10. коэффициент при L2-регуляризации\n",
        "11. количество каналов(НОК)\n",
        "12. параметр для планировщика\n",
        "13. начальное значение шага обучения\n",
        "14. размер ядра свёртки\n",
        "15. шаг при свёртке\n",
        "16. размер паддинга\n",
        "17. вид датасета\n",
        "18. номер модели\n",
        "\n",
        "Б) функции:\n",
        "\n",
        "1. init, принимающий dict, описывающий конфигурацию модели, оптимизатора и планировщика, инициализация модели, инициализация оптимизатора и планировщика\n",
        "2. обучение на 1 батче\n",
        "3. валидация на 1 батче\n",
        "4. тест на 1 батче\n",
        "5. переход с следующей эпохе: сохраняем значение функции потерь, лучшую модель\n",
        "6. отрисовка кривых обучения на обучении и валидации\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5eh9HEGHh5F"
      },
      "source": [
        "class Trainer(object):\n",
        "  def __init__(self, parametr):\n",
        "    \n",
        "    self.model = Net_encoder_decoder(k_s =parametr['k_size'],    #kernel_size\n",
        "                                     strid=parametr['stride'],   #stride\n",
        "                                     pad=parametr['padd'],       #padding\n",
        "                                     canal = parametr['chanal']) #channals\n",
        "    self.model.apply(init_weight)\n",
        "\n",
        "    for param in self.model.parameters():\n",
        "      param.requires_grad = True\n",
        "    \n",
        "    if parametr['optim'] == \"Adam\":\n",
        "      self.optimizer = torch.optim.Adam((self.model).parameters(), lr=parametr['learn_rate'],\n",
        "                                        weight_decay = parametr['lambda_L2'])\n",
        "    elif parametr['optim'] == \"RAdam\":\n",
        "      self.optimizer = optim.RAdam((self.model).parameters(), lr=parametr['learn_rate'],\n",
        "                                   weight_decay = parametr['lambda_L2'])\n",
        "    \n",
        "    if parametr['sheduler'] ==True:\n",
        "      self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, patience=parametr['shed_patience'], \n",
        "                                                                  factor=0.5, verbose=True)\n",
        "    \n",
        "\n",
        "    self.lambda_L1 = parametr['lambda_L1']\n",
        "\n",
        "    self.lambda_L2 = parametr['lambda_L2']\n",
        "\n",
        "    self.learn_rate = parametr['learn_rate']\n",
        "\n",
        "    self.shed_patience = parametr['shed_patience']\n",
        "\n",
        "    self.optimizer_type = parametr['optim']\n",
        "\n",
        "    self.kernel_size = parametr['k_size']\n",
        "\n",
        "    self.stride = parametr['stride']\n",
        "\n",
        "    self.padding = parametr['padd']\n",
        "\n",
        "    self.channals = parametr['chanal']\n",
        "\n",
        "    self.type_data = parametr['type_data']\n",
        "\n",
        "    self.arсhitecture = parametr['arсhitecture']\n",
        "\n",
        "    self.loss = parametr['loss']\n",
        "\n",
        "    self.train_loss =[]\n",
        "    \n",
        "    self.valid_loss =[]\n",
        "\n",
        "    self.train_loss_batch =[]\n",
        "    \n",
        "    self.valid_loss_batch =[]\n",
        "\n",
        "    self.test_loss_batch =[]\n",
        "\n",
        "    self.best_model = copy.deepcopy(self.model)\n",
        "\n",
        "    self.best_val_loss = float('inf')\n",
        "\n",
        "    self.index = parametr['index'] ## идентификатор модели\n",
        "\n",
        "\n",
        "  def train(self,data,device):\n",
        "    loss_fun = My_Loss() \n",
        "    \n",
        "    self.model.train()\n",
        "    train_running_loss = 0\n",
        "    \n",
        "    input = data\n",
        "\n",
        "    preds = (self.model).forward(input)\n",
        "    loss_value = loss_fun(preds,input, self.loss) + self.lambda_L1*reg_L1(self.model)\n",
        "\n",
        "    self.optimizer.zero_grad()\n",
        "    loss_value.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "    train_running_loss = loss_value.item()\n",
        "    \n",
        "    self.train_loss_batch.append(train_running_loss)\n",
        "\n",
        "\n",
        "  def valid(self,data, device):\n",
        "\n",
        "    loss_fun = My_Loss() \n",
        "\n",
        "    self.model.eval()\n",
        "    valid_running_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      input = data\n",
        "      preds = (self.model).forward(input)\n",
        "      loss_value = loss_fun(preds,input, self.loss) + self.lambda_L1*reg_L1(self.model)\n",
        "      valid_running_loss = loss_value.item()\n",
        "        \n",
        "    self.valid_loss_batch.append(valid_running_loss)\n",
        "\n",
        "  def jump(self,epoch):  ## переход с следующей эпохе: сохраняем значение функции потерь, лучшую модель\n",
        "    train_epoch_loss = sum(self.train_loss_batch) / len(self.train_loss_batch)\n",
        "    self.train_loss.append(train_epoch_loss)\n",
        "    output('Epoch '+str(epoch)+' for model' +str(self.index) + ' train loss='+str(train_epoch_loss))\n",
        "\n",
        "    valid_epoch_loss = sum(self.valid_loss_batch) / len(self.valid_loss_batch)\n",
        "    self.valid_loss.append(valid_epoch_loss)\n",
        "\n",
        "    self.valid_loss_batch =[]\n",
        "    self.test_loss_batch =[]\n",
        "    \n",
        "    if valid_epoch_loss < self.best_val_loss:\n",
        "      self.best_val_loss = valid_epoch_loss\n",
        "      self.best_model = copy.deepcopy(self.model)\n",
        "\n",
        "      output('Epoch '+str(epoch)+' Новая лучшая модель '+str(self.index) +'! loss='+str(valid_epoch_loss))\n",
        "\n",
        "      torch.save(self.model, \n",
        "                 os.path.join(path_result, \"e0_e3_d3_d6__{}.pth\".format(self.index)))\n",
        "      \n",
        "      pickle.dump(self.scheduler.state_dict(),\n",
        "                  open(os.path.join(path_result,\"schedular_dict_e0_e3_d3_d6__{}.p\".format(self.index)),\n",
        "                       \"wb\"))\n",
        "    else:\n",
        "      output('Epoch '+str(epoch)+'for model'+str(self.index) +'valid loss='+str(valid_epoch_loss))\n",
        "\n",
        "    self.scheduler.step(valid_epoch_loss)\n",
        "\n",
        "  def plot_res(self,epoches):\n",
        "    plt.plot(range(epoches), self.train_loss,'b', label = 'train')\n",
        "    plt.plot(range(epoches), self.valid_loss,'r', label = 'valid')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(os.path.join(path_result,\"e0_e3_d3_d6__{}__loss.png\".format(self.index)))\n",
        "    plt.show()\n",
        "\n",
        "  def tested(self,data, device,k):\n",
        "\n",
        "    loss_fun = My_Loss() \n",
        "\n",
        "    self.best_model.eval()\n",
        "    test_running_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      input = data\n",
        "\n",
        "      preds = self.best_model.forward(input)\n",
        "      loss_value = loss_fun(preds,input, self.loss) + self.lambda_L1*reg_L1(self.model)\n",
        "      test_running_loss = loss_value.item()\n",
        "\n",
        "      unloader = transforms.ToPILImage() \n",
        "      plt.figure(figsize = (12,5))\n",
        "\n",
        "      plt.subplot(1,2,1)\n",
        "      plt.imshow(unloader(input.reshape(3,512,512)))\n",
        "      plt.title(\"In\")\n",
        "\n",
        "      plt.subplot(1,2,2)\n",
        "      plt.imshow(unloader(preds.reshape(3,512,512)))\n",
        "      plt.title(\"Out\")\n",
        "       \n",
        "      if k==0 or k==40:\n",
        "        plt.savefig(os.path.join(path_result,\"e0_e3_d3_d6__{}__res__{}.png\".format(self.index,k)),bbox_inches=\"tight\")\n",
        "      if k<100:\n",
        "        plt.show()\n",
        "    self.test_loss_batch.append(test_running_loss)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYVicP-_qXw8"
      },
      "source": [
        "### Создание датасетов "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFKy4MHrHsRQ",
        "outputId": "4d311357-9abd-479f-a69b-a1e67a552371"
      },
      "source": [
        "train_dataset = DogDataset(path,0)\n",
        "valid_dataset = DogDataset(path,1)\n",
        "test_dataset = DogDataset(path,2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество файлов: 9000\n",
            "Количество файлов: 3000\n",
            "Количество файлов: 2630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRZM4nEZqhWp"
      },
      "source": [
        "### Задание параметров модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyzQ6Tc1NTSN"
      },
      "source": [
        "df_Info = pd.read_csv(os.path.join(path_result,\"INFO_e0_e3_d3_d6.csv\"), header = 0, index_col = 0) "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP5-1lh-Hu7b"
      },
      "source": [
        "epoches = 50\n",
        "batch_size = 20\n",
        "\n",
        "parametr_1 = {'index': df_Info.shape[0]+1, 'k_size': 4, 'stride':2, 'padd':1, 'chanal': 32, 'optim' : \"RAdam\", \n",
        "              'lambda_L1': 0.00001, 'lambda_L2' : 0.0001,  'learn_rate': 1.0e-3, 'sheduler':True, 'shed_patience': 5,\n",
        "              'arсhitecture': '3---6', 'loss':\"MSE\",\"type_data\": \"dogs_cats_wild\"}\n",
        "\n",
        "model_1 = Trainer(parametr_1)\n",
        "\n",
        "models = [model_1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_kN6axiQIKZ"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrRvk1aaQeAE"
      },
      "source": [
        "for m in models:\n",
        "  m.model = m.model.to(device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRDDR9SNqwx6"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN4QBLD0Hom-"
      },
      "source": [
        "def train_epoch(models, train_dataset,valid_dataset, num_epochs, batch_size, device):\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "  \n",
        "  valid_loader = torch.utils.data.DataLoader(\n",
        "    valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4, drop_last=True)\n",
        "  \n",
        "  output('Start train '+str(num_epochs)+' epochs')\n",
        "\n",
        "  for epoch in (tqdm(range(num_epochs)) if opt.colab else range(num_epochs)):\n",
        "    for input in train_loader:\n",
        "      input = input.to(device)\n",
        "\n",
        "      for m in models:\n",
        "        m.train(input, device)\n",
        "    for input in valid_loader:\n",
        "      input = input.to(device)\n",
        "\n",
        "      for m in models:\n",
        "        m.valid(input, device)\n",
        "\n",
        "    for m in models:\n",
        "      m.jump(epoch)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vJtUXGYQhLS"
      },
      "source": [
        "train_epoch(models, train_dataset,valid_dataset, epoches, batch_size, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2AxQmYPq37C"
      },
      "source": [
        "### Кривая обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzBMMxNHR3qM"
      },
      "source": [
        "model_1.plot_res(epoches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_wgvqQUq8-V"
      },
      "source": [
        "### Тестирование модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haAeClkAa41s"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=1, shuffle=False, num_workers=4, drop_last=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkSd7MS1a5HO"
      },
      "source": [
        "def pred(model, loader,device, s):\n",
        "\n",
        "  k=0;\n",
        "  for input in loader:\n",
        "    input = input.to(device)\n",
        "    model.tested(input, device,k)\n",
        "    k+=1\n",
        "    if k>100:\n",
        "      break\n",
        "  \n",
        "  return(sum(model.test_loss_batch) / len(loader))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J7OoEnza5P9"
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].model = torch.load(os.path.join(path_result, \"e0_e3_d3_d6__{}.pth\".format(models[i].index)))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "800v2LNEa5lH"
      },
      "source": [
        "def save_param(model,epoches, batch_size):\n",
        "    df_Info = pd.read_csv(os.path.join(path_result,\"INFO_e0_e3_d3_d6.csv\"), header = 0, index_col = 0)\n",
        "\n",
        "    test_loss = pred(model, test_loader,device, [0,40])\n",
        "    \n",
        "    last_lr_1 = (pickle.load(open(os.path.join(path_result,\"schedular_dict_e0_e3_d3_d6__{}.p\".format(model.index)),\n",
        "                                  \"rb\")))['_last_lr'][0]\n",
        "\n",
        "    df_Info.loc[model.index] = [epoches, batch_size, model.lambda_L1, model.lambda_L2, model.learn_rate, last_lr_1,\n",
        "                                test_loss, model.shed_patience, model.optimizer_type, model.kernel_size,\n",
        "                                model.stride, model.padding, model.channals, model.arсhitecture, model.loss, \n",
        "                                model.type_data]\n",
        "\n",
        "    df_Info.to_csv(os.path.join(path_result,\"INFO_e0_e3_d3_d6.csv\"))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGach8hTbjpZ"
      },
      "source": [
        "save_param(model_1,epoches, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xJ4UHcvbjx9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYHGnsnMbj_M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkSbhXZGaxGn"
      },
      "source": [
        "### Сжатие 1 картинки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPr_yUJ2bsJQ"
      },
      "source": [
        "def pred_from_model(model, loader,device):\n",
        "\n",
        "  k=0;\n",
        "  for input in loader:\n",
        "    input = input.to(device)\n",
        "    pred_for_1_foto(model,input, device)\n",
        "    k+=1\n",
        "    if k>100:\n",
        "      break\n",
        "  \n",
        "  return(sum(model.test_loss_batch) / len(loader))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBnmTI0UbsV-"
      },
      "source": [
        "def pred_for_1_foto(model,input, device):\n",
        "    \n",
        "    trans = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])\n",
        "    \n",
        "    input = trans(Image.open(input)) # тензор размером [3,512,512], где значения от 0 до \n",
        "    \n",
        "    print(input.shape)\n",
        "\n",
        "    input = input.reshape(1,3,512,512)\n",
        "\n",
        "    input = input.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      for i in range(len(model)):\n",
        "        if i ==0:\n",
        "          preds = model[i].forward(input)\n",
        "        else:\n",
        "          preds += model[i].forward(input)\n",
        "\n",
        "      preds /= len(model)\n",
        "      \n",
        "      unloader = transforms.ToPILImage() \n",
        "      plt.figure(figsize = (12,5))\n",
        "\n",
        "      plt.subplot(1,2,1)\n",
        "      plt.imshow(unloader(input.reshape(3,512,512)))\n",
        "      plt.title(\"In\")\n",
        "      \n",
        "      plt.subplot(1,2,2)\n",
        "      plt.imshow(unloader(preds.reshape(3,512,512)))\n",
        "      plt.title(\"Out\")\n",
        "      plt.show()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjmJjIw7bsdy"
      },
      "source": [
        "index_model_1_foto = [51]\n",
        "model_for_1_foto = []\n",
        "for i in index_model_1_foto:\n",
        "  model_for_1_foto.append(torch.load(os.path.join(path_result, \"e0_e3_d3_d6__{}.pth\".format(i))))\n",
        "pred_for_1_foto(model_for_1_foto,\"./1.jpg\", device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr7Qg5gmb6lJ"
      },
      "source": [
        "### Сжатие видео"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZN4nHo6b7k5"
      },
      "source": [
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t2YLKuWb70-"
      },
      "source": [
        "!mkdir new_foto_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atg7wgWYb8zs"
      },
      "source": [
        "score = []\n",
        "\n",
        "def pred_for_foto(model,input, device,s):\n",
        "    \n",
        "    trans = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])\n",
        "    \n",
        "    input = trans(Image.open(input)) # тензор размером [3,512,512], где значения от 0 до \n",
        "    \n",
        "    input = input.reshape(1,3,512,512)\n",
        "\n",
        "    input = input.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      preds = model.forward(input)\n",
        "\n",
        "      func_loss = torch.nn.MSELoss()\n",
        "      score.append(func_loss(preds, input))\n",
        "\n",
        "      unloader = transforms.ToPILImage() \n",
        "      plt.figure(figsize = (12,5))\n",
        "\n",
        "      plt.subplot(1,2,1)\n",
        "      plt.imshow(unloader(input.reshape(3,512,512)))\n",
        "      plt.title(\"In\")\n",
        "      \n",
        "      plt.subplot(1,2,2)\n",
        "      plt.imshow(unloader(preds.reshape(3,512,512)))\n",
        "      plt.title(\"Out\")\n",
        "      plt.savefig(\"/content/new_foto_4/new_foto__{}.png\".format(s),bbox_inches=\"tight\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqEyuzw_cE0L"
      },
      "source": [
        "# Читать видео по указанному пути\n",
        "\n",
        "cam = cv2.VideoCapture(\"./1.mp4\")\n",
        "\n",
        "\n",
        "try:\n",
        "\n",
        "    # создание папки с именем data\n",
        "\n",
        "    if not os.path.exists('/content/foto_4'):\n",
        "\n",
        "        os.makedirs('foto_4')\n",
        "\n",
        "# если не создано, то выдайте ошибку\n",
        "\n",
        "except OSError:\n",
        "    print ('Error: Creating directory of data')\n",
        "\n",
        "  \n",
        "# Рамка\n",
        "\n",
        "currentframe = 1000\n",
        "\n",
        "  \n",
        "\n",
        "while(True):\n",
        "    # чтение из кадра\n",
        "\n",
        "    ret,frame = cam.read()\n",
        "\n",
        "    if ret:\n",
        "\n",
        "        # если видео еще осталось, продолжайте создавать изображения\n",
        "\n",
        "        name = '/content/foto_4/frame' + str(currentframe) + '.jpg'\n",
        "\n",
        "        print ('Creating...' + name)\n",
        "\n",
        "        # запись извлеченных изображений\n",
        "\n",
        "        cv2.imwrite(name, frame)\n",
        "\n",
        "  \n",
        "\n",
        "        # увеличение счетчика, чтобы оно было\n",
        "\n",
        "        # показать, сколько кадров создано\n",
        "\n",
        "        currentframe += 1\n",
        "\n",
        "    else:\n",
        "\n",
        "        break\n",
        "\n",
        "  \n",
        "# Освободить все пространство и окна, как только сделано\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3DW9RyCcJK3"
      },
      "source": [
        "index_model_1_foto = 51\n",
        "model_for_1_foto = torch.load(os.path.join(path_result, \"e0_e3_d3_d6__{}.pth\".format(index_model_1_foto)))\n",
        "\n",
        "mas = sorted(Path(\"/content/foto_4\").glob('*.jpg'))\n",
        "s=1000\n",
        "for im in tqdm(mas):\n",
        "  pred_for_foto(model_for_1_foto,im, device,s)\n",
        "  s+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkrTQlmBcQra"
      },
      "source": [
        "print(len(score))\n",
        "print(\"Точность сжатия-разжатия: \", (1-torch.mean(torch.tensor(score)))*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u2W54sMcg0Z"
      },
      "source": [
        "import imageio\n",
        "fileList = []\n",
        "filenames = sorted(Path(\"/content/new_foto_6\").glob('*.png'))\n",
        "for file in filenames:\n",
        "    fileList.append(file)\n",
        "\n",
        "writer = imageio.get_writer('/content/3.mp4', fps=20)\n",
        "\n",
        "for im in fileList:\n",
        "    writer.append_data(imageio.imread(im))\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}